{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Chatbot Framework\n",
    "\n",
    "State-machine to handle responses using the intents model (previous) as classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for NLP\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "# for tensorflow\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# for files\n",
    "import json\n",
    "\n",
    "# model export / import\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore data-structures\n",
    "\n",
    "Restore the data structure previously saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load( open( \"data/training_data.pkl\", \"rb\" ) )\n",
    "\n",
    "words = data['words']\n",
    "classes = data['classes']\n",
    "train_x = data['train_x']\n",
    "train_y = data['train_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/intents.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Saved Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Structure\n",
    "\n",
    "First, we define the model structure used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tflearn/objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# reset underlying graph data\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Build Neural Network\n",
    "net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "# Define model and setup tensorboard\n",
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Model\n",
    "\n",
    "The already trained & saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /notebooks/NLP/ContextualChatbot/exports/model.tflearn\n"
     ]
    }
   ],
   "source": [
    "model.load(model_file='exports/model.tflearn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bag of Words from User Input\n",
    "\n",
    "Array with 0's and 1's fow words wich exist in the patterns (sentences) we have in the intents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of invalid words\n",
    "invalid_words = [\"?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # tokenize\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    # stem words\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words if word not in invalid_words]\n",
    "    \n",
    "    return sentence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['which', 'mop', 'do', 'you', 'hav']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_up_sentence(\"Which mopeds do you have?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW function\n",
    "\n",
    "Returns bag of words array \n",
    "\n",
    "0 or 1 for each word in the sentence that exists in the bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(sentence, words, show_details=False):\n",
    "    # tokenize\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    \n",
    "    # \"Tensor\" of zeros\n",
    "    bag = [0] * len(words)\n",
    "    \n",
    "    # loop through all words in the sentence tested\n",
    "    for sentence_word in sentence_words:\n",
    "        \n",
    "        # loop through all words in the defined intents\n",
    "        for index, word in enumerate(words):\n",
    "            if word == sentence_word:\n",
    "                bag[index] = 1\n",
    "                \n",
    "                if show_details:\n",
    "                    print(\"word found in bag: %s\" % word)\n",
    "\n",
    "    return (np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word found in bag: ar\n",
      "word found in bag: you\n",
      "word found in bag: today\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow(\"Are you attending today?\", words, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Response Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {}\n",
    "ERROR_THRESHOLD = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify\n",
    "\n",
    "First, classify the sentence based in the `patterns` and `tags` in intents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(sentence):\n",
    "    # generate probabilities from the model\n",
    "    results = model.predict( [bow(sentence, words)] )[0]\n",
    "    \n",
    "    # filter out predictions below threshold\n",
    "    results = [[index,result] for index,result in enumerate(results) if result > ERROR_THRESHOLD]\n",
    "    \n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return_list = []\n",
    "    \n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], r[1]))\n",
    "        \n",
    "    # tuple of intent and probability\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rental', 0.67940056)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"I want a moped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('today', 0.521593), ('opentoday', 0.31226322)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"Hours for today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('payments', 0.7292963)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"I only have cash for pay?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response\n",
    "\n",
    "Explore tags for classification results and give a random response from that tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(sentence, userID=\"123\", show_details=False):\n",
    "    results = classify(sentence)\n",
    "    \n",
    "    # if classification have results, find the matching intent tag\n",
    "    if results:\n",
    "        # loop all results\n",
    "        while results:\n",
    "            for intent in intents['intents']:\n",
    "                # find the matching tag\n",
    "                if intent['tag'] == results[0][0]:\n",
    "                    # random response from the intent\n",
    "                    return print(random.choice(intent['responses']))\n",
    "            \n",
    "            results.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(sentence, userID=\"123\", show_details=False):\n",
    "    results = classify(sentence)\n",
    "    \n",
    "    # if classification have results, find the matching intent tag\n",
    "    if results:\n",
    "        # loop all results\n",
    "        while results:\n",
    "            for intent in intents['intents']:\n",
    "                # find the matching tag\n",
    "                if intent['tag'] == results[0][0]:\n",
    "                    # set context for this intent\n",
    "                    if 'context_set' in intent:\n",
    "                        if show_details: print ('context: ', intent['context_set'])\n",
    "                        \n",
    "                        context[userID] = intent['context_set']\n",
    "\n",
    "                    # check if intent is contextual an apply to user's conversation\n",
    "                    if not 'context_filter' in intent \\\n",
    "                        or (\\\n",
    "                            userID in context \\\n",
    "                            and 'context_filter' in intent \\\n",
    "                            and intent['context_filter'] == context[userID]\\\n",
    "                            ):\n",
    "                        if show_details: print('tag: ', intent['tag'] )\n",
    "                        # random response from the intent\n",
    "                        return print(random.choice(intent['responses']))\n",
    "            \n",
    "            results.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our hours are 9am-9pm every day\n"
     ]
    }
   ],
   "source": [
    "response(\"What hours is open today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We accept most major credit cards\n"
     ]
    }
   ],
   "source": [
    "response(\"I only have cash for pay?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We accept most major credit cards\n"
     ]
    }
   ],
   "source": [
    "response(\"what cards accept?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have Piaggio, Vespa and Yamaha mopeds\n"
     ]
    }
   ],
   "source": [
    "response(\"what kinds of mopeds are here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context:  rentalday\n",
      "tag:  rental\n",
      "Are you looking to rent today or later this week?\n"
     ]
    }
   ],
   "source": [
    "response(\"can rent a moped?\", show_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag:  today\n",
      "For rentals today please call 1-800-MYMOPED\n"
     ]
    }
   ],
   "source": [
    "response(\"today\", show_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'123': 'rentalday'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context:  \n",
      "tag:  greeting\n",
      "Hi there, how can I help?\n"
     ]
    }
   ],
   "source": [
    "response(\"hi there\", show_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response('today', show_details=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
